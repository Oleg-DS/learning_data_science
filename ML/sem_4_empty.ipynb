{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPhMC5u7uMUy"
   },
   "source": [
    "# Линейная классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pSxBYwO6uMU1"
   },
   "source": [
    "Задача классификации заключается в том, чтобы отнести каждый из объектов выборки к какому-либо классу из данного набора. Более формально, нам нужно построить классификатор - функцию $a \\colon X \\rightarrow Y$, которая поставит в соответствие каждому объекту $x$ из пространства объектов $X$ какой-либо класс $y$ из пространства ответов $Y$, где в случае $Y$ - это какое-то конечное множество. То есть, если мы рассмотрим какой-то объект выборки $x$, мы должны получить для него ответ $y = a(x)$.\n",
    "\n",
    "Задачи классификации можно поделить на два типа: бинарная классификация и многоклассовая классификация. В задаче бинарной классификации у нас всего лишь два класса, и множество $Y$ содержит всего два элемента. В задаче же многоклассовой классификации классов больше, чем два.\n",
    "\n",
    "Примеры задач бинарной классификации:\n",
    "\n",
    "- пассажиры с Титаника: выжил ли пассажир? (множество $X$ - пассажиры, множество $Y$ - выжил/нет)\n",
    "- отдаст ли клиент кредит банку? (множество $X$ - клиенты, множество $Y$ - отдаст/нет)\n",
    "- является ли отзыв к товару положительным? (множество $X$ - отзывы, множество $Y$ - положительный/отрицательный)\n",
    "\n",
    "Примеры задач многоклассовой классификации:\n",
    "\n",
    "- какое заболевание у пациента? (множество $X$ - пациенты, множество $Y$ - возможные заболевания)\n",
    "- автоматическое распознавание символов в рукописном тексте (множество $X$ - выделенные в тексте символы, множество $Y$ - словарь символов)\n",
    "- к какому жанру относится данный художественный текст? (множество $X$ - тексты, множество $Y$ - жанры)\n",
    "\n",
    "Для того, чтобы познакомиться с задачей классификации на практике, сгенерируем искусственный датасет, состоящий из 500 объектов. Признаков будет два. Целевая переменная принимает два значения: $-1$ и $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgUZ0y__uMU2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EH710Z_auMU4"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "n = 500\n",
    "X = np.random.normal(size=(n, 2))\n",
    "X[:250, :] += 0.75\n",
    "X[250:, :] -= 1\n",
    "y = np.array([1] * 250 + [-1] * 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LUpJqARuMU6"
   },
   "source": [
    "Визуализируем данные. Построим диаграмму рассеяния по данным признакам, и обозначим объекты разных классов разными цветами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "hSijDADiuMU6",
    "outputId": "a2620fa8-045f-4bb0-d366-a6e296cc97f7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], cmap='winter', s=100, label='objects of class y = 1')\n",
    "plt.scatter(X[y == -1, 0], X[y == -1, 1], cmap='winter', s=100, label='objects of class y = -1')\n",
    "plt.title('Scatterplot of the generated data')\n",
    "plt.xlabel('feature #1')\n",
    "plt.ylabel('feature #2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Xv2m0jWuMU8"
   },
   "source": [
    "Перед нами стоит задача - разделить объекты на два класса. На картинке видно, что представители этих классов более-менее отделены друг от друга, и почти не перемешиваются. Но как же решить задачу с помощью машинного обучения? Напомним, что задача заключается в построении алгоритма (функции $a(x)$), который позволит классифицировать **любой** объект из пространства возможных объектов.\n",
    "\n",
    "Есть различные типы моделей машинного обучения, которые позволяют решить данную задачу. Одним из типов моделей являются линейные классификаторы. Их особенность заключается в том, что решение о принадлежности объекта к какому-либо классу принимается на основе **линейной комбинации** его характеристик (значений признаков). Предположим, что в датасете $d$ признаков, то есть каждый объект $x$ имеет $d$ характеристик - $x_1, x_2, \\ldots, x_d$. Тогда ответ линейного классификатора будет получаться по следующей формуле:\n",
    "\n",
    "$$\n",
    "y = f\\left(\\sum\\limits_{j = 1}^d w_jx_j\\right), \\qquad\\qquad (1)\n",
    "$$\n",
    "\n",
    "где $f$ - какая-то функция, подходящая по смыслу нашей задаче (выдающая конечное множество значений - классов), а $w_j$ - веса классификатора. Понятно, что так как мы можем выбрать любую разумную $f$, мы можем \"сдвинуть\" параметр функции $f$ на некоторое число $w_0$. Тогда можно переписать формулу $(1)$ следующим образом, добавив еще один вес - $w_0$:\n",
    "\n",
    "$$\n",
    "y = f\\left(w_0 + \\sum\\limits_{j = 1}^d w_jx_j\\right) \\qquad\\qquad (2)\n",
    "$$\n",
    "\n",
    "Какую же функцию $f$ мы можем выбрать? В задаче бинарной классификации $f$ может быть функцией, которая выдает разные ответы в зависимости от того, какой знак (плюс или минус) имеет рассматриваемое значение:\n",
    "\n",
    "$$\n",
    "y = \\operatorname{sign}\\left(w_0 + \\sum\\limits_{j = 1}^d w_jx_j\\right) = \\begin{cases} 1, & w_0 + \\sum\\limits_{j = 1}^d w_jx_j \\geq 0 \\\\ -1, & w_0 + \\sum\\limits_{j = 1}^d w_jx_j < 0 \\end{cases} \\qquad\\qquad (3)\n",
    "$$\n",
    "\n",
    "Кстати, если в качестве $f$ выбрать сигмоидную функцию, то получится логистическая регрессия, где на выходе получается вероятность положительного класса:\n",
    "\n",
    "$$\n",
    "y = \\sigma\\left(w_0 + \\sum\\limits_{j = 1}^d w_jx_j\\right) = \\frac{1}{1 + \\exp\\left(-w_0 - \\sum\\limits_{j = 1}^d w_jx_j\\right)}\n",
    "$$\n",
    "\n",
    "Давайте более детально разберем, что мы получили. Приравняем рассматриваемое \"сдвинутое\" значение линейной комбинации к нулю:\n",
    "\n",
    "$$\n",
    "w_0 + \\sum\\limits_{j = 1}^d w_jx_j = 0 \\qquad\\qquad (4)\n",
    "$$\n",
    "\n",
    "Это очень похоже на уравнение прямой на плоскости, в котором также есть переменные ($x_1$ и $x_2$), веса ($a$ и $b$) и свободный коэффициент ($c$):\n",
    "\n",
    "$$\n",
    "ax_1 + bx_2 + c = 0\n",
    "$$\n",
    "\n",
    "Формула $(4)$ - это уравнение **гиперплоскости**, что является обобщением прямой на плоскости на пространства любых размерностей. Если говорить строго, прямая является подпространством размерности $1$ пространства размерности $2$ (плоскости), то есть ее размерность на $1$ меньше, чем у исходного пространства. А гиперплоскость - подпространство размерности $d - 1$ пространства размерности $d$.\n",
    "\n",
    "Таким образом, уравнение $(4)$ соответствует гиперплоскости размерности $d - 1$ в пространстве размерности $d$. В таком случае уравнение $(3)$ показывает, **по какую сторону от гиперплоскости лежит объект**. Если объект лежит по одну сторону от гиперплоскости, то он относится к положительному классу, если по другую - к отрицательному. Получается, что данный классификатор строит **разделяющую гиперплоскость**, разделяющую пространство на две области - один класс и другой.\n",
    "\n",
    "Для наглядности разберем случай $d = 2$ на примере сгенерированного ранее датасета. Уравнение разделяющей гиперплоскости (прямой) будет выглядеть так:\n",
    "\n",
    "$$\n",
    "w_0 + w_1x_1 + w_2x_2 = 0\n",
    "$$\n",
    "\n",
    "Зададим веса $w_0 = w_1 = w_2 = 1$ и посмотрим на прямую, которая получится в результате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "h3_JfU8vuMU9",
    "outputId": "692e0934-e9a3-4b91-82d3-183b949cd83b"
   },
   "outputs": [],
   "source": [
    "w0 = 1\n",
    "w1 = 1\n",
    "w2 = 1\n",
    "x1 = np.linspace(X[:, 0].min(), X[:, 0].max(), 1000)\n",
    "x2 = (- w1 * x1 - w0) / w2\n",
    "\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], cmap='winter', s=100, label='objects of class y = 1')\n",
    "plt.scatter(X[y == -1, 0], X[y == -1, 1], cmap='winter', s=100, label='objects of class y = -1')\n",
    "plt.plot(x1, x2, color='green', label='separating hyperplane')\n",
    "plt.title('Scatterplot of the generated data')\n",
    "plt.xlabel('feature #1')\n",
    "plt.ylabel('feature #2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "Добавим в данные единичный признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = np.array([1.0, 1.0, 1.0])\n",
    "X_new = np.c_[np.ones(n), X]\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CEORpjnuMU-"
   },
   "source": [
    "Видно, что прямая неплохо разделяет классы. Однако мы сделали только первое предположение о весах гиперплоскости, и оптимальное качество разбиения можно попробовать получить с помощью градиентного спуска. Для этого, как было сделано в лекции, можно выбрать логистическую функцию потерь:\n",
    "\n",
    "$$\n",
    "\\tilde{Q}(w, X) = \\frac{1}{\\ell}\\sum\\limits_{i=1}^\\ell\\log\\left(1 + \\exp(-y_i\\langle w, x_i\\rangle)\\right) \\rightarrow \\min_w\n",
    "$$\n",
    "\n",
    "Здесь $\\ell$ - количество объектов в данных (в нашем случае $\\ell = 500$), $w$ - вектор весов, $x_i$ - признаковое описание $i$-ого объекта. Для удобства мы предполагаем, что в данных есть единичный признак (который соответствует весу $w_0$), поэтому левая часть уравнения $(4)$ превращается в скалярное произведение:\n",
    "\n",
    "$$\n",
    "\\langle w, x\\rangle = 0\n",
    "$$\n",
    "\n",
    "Градиент выбранной функции потерь:\n",
    "\n",
    "$$\n",
    "\\nabla_w\\tilde{Q}(w, X) = -\\frac{1}{\\ell}\\sum\\limits_{i=1}^\\ell\\frac{y_ix_i}{1 + \\exp(y_i\\langle w, x_i\\rangle)}\n",
    "$$\n",
    "\n",
    "Формула градиентного спуска:\n",
    "\n",
    "$$\n",
    "w^{(t)} = w^{(t - 1)} - \\eta\\nabla_w\\tilde{Q}(w, X)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Реализуйте формулы функции потерь и ее градиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "h4sb3L9QuMU_",
    "outputId": "0d0f087b-5faf-4aee-a0ac-22a552ed5bb5"
   },
   "outputs": [],
   "source": [
    "def log_loss(w, X, y):\n",
    "    # your code here\n",
    "\n",
    "def log_loss_grad(w, X, y):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98hUsdP1uMVB"
   },
   "source": [
    "Начальное значение функции потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GLzGG9nEuMVB",
    "outputId": "30f25439-4228-4890-dc2b-525239579607"
   },
   "outputs": [],
   "source": [
    "log_loss(w_init, X_new, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zpLAYckguMVD"
   },
   "source": [
    "Начальное значение градиента функции потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fVfL8ZwquMVD",
    "outputId": "bcb6808e-29da-4206-a655-0e4926797f4c"
   },
   "outputs": [],
   "source": [
    "log_loss_grad(w_init, X_new, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DgOU9-5XuMVF"
   },
   "source": [
    "Обучим классификатор с помощью градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LvPFESrquMVF",
    "outputId": "084338e0-f524-4c0a-ccd6-083938aa0206"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_init, n_steps, eta):\n",
    "    w = w_init.copy()\n",
    "    loss_array = [log_loss(w_init, X, y)]\n",
    "    for _ in range(n_steps):\n",
    "        w_grad = log_loss_grad(w, X, y)\n",
    "        w -= eta * w_grad\n",
    "        loss = log_loss(w, X, y)\n",
    "        loss_array.append(loss)\n",
    "    return w, loss_array\n",
    "\n",
    "w, loss_array = gradient_descent(X_new, y, w_init, n_steps=1000, eta=0.1)\n",
    "print('weights:', w)\n",
    "print('loss value:', loss_array[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3BxXdgGuMVH"
   },
   "source": [
    "Нарисуем график падения значения функции потерь в зависимости от номера шага градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "RftAPLnKuMVH",
    "outputId": "8896ee95-224c-4a63-8f64-fed6d8fdb3eb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.plot(loss_array)\n",
    "plt.title('Loss change during gradient descent')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilvfbNoFuMVJ"
   },
   "source": [
    "Визуализируем результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "Li6n3vu6uMVJ",
    "outputId": "338bade0-02fb-404c-b1ce-7cbe9d887cd1"
   },
   "outputs": [],
   "source": [
    "w0 = w[0]\n",
    "w1 = w[1]\n",
    "w2 = w[2]\n",
    "\n",
    "x1 = np.linspace(X[:, 0].min(), X[:, 0].max(), 1000)\n",
    "x2 = (- w1 * x1 - w0) / w2\n",
    "\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], s=100, label='objects of class y = 1')\n",
    "plt.scatter(X[y == -1, 0], X[y == -1, 1], s=100, label='objects of class y = -1')\n",
    "plt.plot(x1, x2, color='green', label='optimal separating hyperplane')\n",
    "plt.title('Scatterplot of the generated data')\n",
    "plt.xlabel('feature #1')\n",
    "plt.ylabel('feature #2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQFgjcETuMVL"
   },
   "source": [
    "В `sklearn` есть готовая реализация линейного классификатора, который можно обучить с помощью градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qcBs2PeuMVM"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='log', learning_rate='constant', eta0=0.1, random_state=13)\n",
    "# заметьте - в данном случае добавлять единичный признак в датасет не нужно, потому что метод SGDClassifier создаст его сам\n",
    "clf.fit(X, y)\n",
    "y_pred_sgdclf = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1zhuKEOuMVN"
   },
   "source": [
    "Посмотрим на получившиеся веса при признаках и на свободный коэффициент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XCOInOwruMVO",
    "outputId": "ab0e7304-d3c4-4cc1-cabc-60d4ac9d739a"
   },
   "outputs": [],
   "source": [
    "clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBwpc89vuMVP"
   },
   "source": [
    "Визуализируем результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "Wokr__9VuMVQ",
    "outputId": "0cf9c4d6-977b-47bb-f48e-6d8e63076c3c"
   },
   "outputs": [],
   "source": [
    "w0_clf = clf.intercept_.item()\n",
    "w1_clf = clf.coef_[0][0]\n",
    "w2_clf = clf.coef_[0][1]\n",
    "x2_clf = (- w1_clf * x1 - w0_clf) / w2_clf\n",
    "\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], s=100, label='objects of class y = 1')\n",
    "plt.scatter(X[y == -1, 0], X[y == -1, 1], s=100, label='objects of class y = -1')\n",
    "plt.plot(x1, x2, color='green', label='optimal separating hyperplane (manual)')\n",
    "plt.plot(x1, x2_clf, color='red', label='optimal separating hyperplane (sklearn)')\n",
    "plt.title('Scatterplot of the generated data')\n",
    "plt.xlabel('feature #1')\n",
    "plt.ylabel('feature #2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ql_RHYJuMVR"
   },
   "source": [
    "# Метрики качества классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ki1iGtnyuMVS"
   },
   "source": [
    "Итак, мы получили оптимальный результат с точки зрения градиентного спуска. Однако на данный момент мы измеряли качество по значению логистической функции потерь (чем меньше, тем лучше), которое неочень понятно, как интерпретировать. Можно ли рассмотреть что-то более интерпретируемое?\n",
    "\n",
    "**Задание:** напишите функцию `predict_classes`, которая возвращает предсказание класса (`1` or `-1`) для каждого объекта из `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aCdIF-5RuMVS",
    "outputId": "21ee9388-9071-4b32-9343-5600e75fe225"
   },
   "outputs": [],
   "source": [
    "def predict_classes(X, w):\n",
    "    # your code here\n",
    "\n",
    "y_pred = predict_classes(X_new, w)\n",
    "y_pred[:6], y_pred[-6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NhQLni8UuMVU"
   },
   "source": [
    "### Доля правильных ответов (accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TolPACekuMVU"
   },
   "source": [
    "Доля правильных ответов - пожалуй, одна из самых тривиальных метрик. Она показывает долю верных предсказаний среди всех объектов:\n",
    "\n",
    "$$\n",
    "\\text{accuracy}(a, X) = \\frac{1}{\\ell}\\sum\\limits_{i=1}^\\ell [a(x_i) = y_i]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pLUxgwpnuMVV",
    "outputId": "7e36e779-ff93-4d92-eae4-25530957a100"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RSY3GCEuMVW"
   },
   "source": [
    "Итак, алгоритм предсказывает верно 90.4% объектов. Для более детального анализа можно построить матрицу ошибок:\n",
    "\n",
    "|           | y = 1               | y = -1              |\n",
    "|-----------|---------------------|---------------------|\n",
    "| a(x) = 1  | True Positive (TP)  | False Positive (FP) |\n",
    "| a(x) = -1 | False Negative (FN) | True Negative (TN)  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "soyCIbKvuMVX",
    "outputId": "5799e288-b820-4bbe-ea7d-4e20c1ae3bd4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGXYTNX0uMVa"
   },
   "source": [
    "Итак, в данном примере алгоритм неправильно классифицирует 21 объект положительного класса и 27 объектов отрицательного класса.\n",
    "\n",
    "Проблема метрики accuracy в том, что она не учитывает цену ошибки, и дает обманчивый результат в случае несбалансированной выборки, о чем рассказывалось в лекции. Следующие метрики позволяют акцентировать большее внимание на разные виды ошибок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOtAnsNYuMVb"
   },
   "source": [
    "### Точность (precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_otnZ_D3uMVb"
   },
   "source": [
    "Точность показывает долю верно предсказанных положительных объектов среди всех предсказаний положительного класса:\n",
    "\n",
    "$$\n",
    "\\text{precision}(a, X) = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tqUMDsiOuMVc",
    "outputId": "d45f771e-2059-4ace-cfc5-91319ff7b278"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GfarP__uMVd"
   },
   "source": [
    "### Полнота (recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZ6RXQgSuMVe"
   },
   "source": [
    "Полнота показывает долю верно предсказанных положительных объектов среди всех положительных объектов в данных:\n",
    "\n",
    "$$\n",
    "\\text{recall}(a, X) = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cNb08luAuMVe",
    "outputId": "26b0a58b-aeeb-41e7-de58-3aa165642fe2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-zXdUWYuMVg"
   },
   "source": [
    "Точность и полнота в данном случае показывают похожий результат, потому что модель примерно одинаково ошибается в классификации объектов положительного и отрицательного классов. В реальных задачах можно максимизировать точность или полноту в зависимости от того, какой вид ошибок мы не хотим допускать. Однако обычно при максимизации одной из этих метрик значение другой ухудшается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KyXzOhEeuMVg"
   },
   "source": [
    "### F-мера (F-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIXcUgwsuMVh"
   },
   "source": [
    "F-мера - это метрика, находящая некоторый баланс между точностью и полнотой. Ее значение - это их гармоническое среднее:\n",
    "\n",
    "$$\n",
    "\\text{F-score}(a, X) = 2\\frac{\\text{precision}(a, X)\\cdot\\text{recall}(a, X)}{\\text{precision}(a, X) + \\text{recall}(a, X)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WZcm7VXguMVh",
    "outputId": "39c141ab-f6b2-4a5c-b237-a6ed41f8345f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jC6cPNCOuMVj",
    "outputId": "cbb7f26c-85f5-4422-ea3a-a5c1da81a216"
   },
   "outputs": [],
   "source": [
    "# проверим, что формула выше дает такой же ответ\n",
    "2 * precision_score(y, y_pred) * recall_score(y, y_pred) / (precision_score(y, y_pred) + recall_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZsNx9KguMVk"
   },
   "source": [
    "Если какой-либо из метрик (точности или полноте) необходимо отдать приоритет, можно использовать взвешенную версию F-меры - с положительным параметром $\\beta$:\n",
    "\n",
    "$$\n",
    "\\text{F-score}_\\beta(a, X) = (1 + \\beta^2)\\frac{\\text{precision}(a, X)\\cdot\\text{recall}(a, X)}{\\beta^2\\text{precision}(a, X) + \\text{recall}(a, X)}\n",
    "$$\n",
    "\n",
    "Если $0 < \\beta < 1$, то нам важнее точность. Это легко проверить, устремив $\\beta$ к $0$ - в таком случае в выражении выше останется лишь точность. Если $\\beta > 1$, то нам важнее полнота - проверяется это аналогичным образом, устремлением $\\beta$ к бесконечности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fWR_BFjSuMVl",
    "outputId": "71ac20cb-b76c-4251-ded9-e208543c7325"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "beta = 0.5\n",
    "fbeta_score(y, y_pred, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPmIiHbOuMVm"
   },
   "source": [
    "### PR-кривая и AUC-PRC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Wc8JqTBuMVn"
   },
   "source": [
    "Вместо того, чтобы предсказывать один из классов в задаче классификации, можно предсказывать вероятность принадлежности одному из классов. А именно, построить алгоритм $b(x)$, который вместо чисел $1$ и $-1$ будет выдавать вещественное число от $0$ до $1$ - вероятность того, что объект принадлежит классу $1$. Скажем, если $b(x) = 0.98$, то можно заключить, что по мнению алгоритма объект $x$ принадлежит классу $1$ с вероятностью $98\\%$. Для того, чтобы из предсказаний затем все же получить один из классов $1$ или $-1$, можно задать порог $t$ и использовать алгоритм $a(x) = [b(x) > t]$. Одной из таких моделей является, например, логистическая регрессия. \n",
    "\n",
    "**Задание:** напишите функцию `predict_probabilities`, которая возвращает вероятность принадлежности к классу `1` для каждого объекта из `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "B7Himk0auMVn",
    "outputId": "e53d6169-6538-4010-f070-2148c81adbe4"
   },
   "outputs": [],
   "source": [
    "def predict_probabilities(X, w):\n",
    "    # your code here\n",
    "\n",
    "y_pred_prob = predict_probabilities(X_new, w)\n",
    "y_pred_prob[:6], y_pred_prob[-6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе из `predict_probabilities` получается число от $0$ до $1$, и чтобы получить класс в качестве ответа, можно задать порог $t$ равный, к примеру, $0.5$.\n",
    "\n",
    "**Задание:** напишите функцию `threshold`, которая возвращает вероятность предсказание класса (`1` or `-1`) используя вектор вероятностей и порог $t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "n0PzIRCkuMVq",
    "outputId": "0235a450-adf8-4f7f-cae0-a72595e7005e"
   },
   "outputs": [],
   "source": [
    "def threshold(y_pred_prob, t):\n",
    "    # your code here\n",
    "\n",
    "t = 0.5\n",
    "y_pred_t = threshold(y_pred_prob, t)\n",
    "print('t =', t)\n",
    "print('Precision:', precision_score(y, y_pred_t))\n",
    "print('Recall:', recall_score(y, y_pred_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "je6xQxJVuMVs",
    "outputId": "79a5ecce-6ffe-426d-faad-eb0045553878"
   },
   "outputs": [],
   "source": [
    "t = 0.75\n",
    "y_pred_t = threshold(y_pred_prob, t)\n",
    "print('t =', t)\n",
    "print('Precision:', precision_score(y, y_pred_t))\n",
    "print('Recall:', recall_score(y, y_pred_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "HLAD_aq5uMVu",
    "outputId": "74d90d02-375b-4b08-f974-2a726ede837b"
   },
   "outputs": [],
   "source": [
    "t = 0.25\n",
    "y_pred_t = threshold(y_pred_prob, t)\n",
    "print('t =', t)\n",
    "print('Precision:', precision_score(y, y_pred_t))\n",
    "print('Recall:', recall_score(y, y_pred_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vDEk0OduMVv"
   },
   "source": [
    "**Как выбрать порог?** Для ответа на этот вопрос, и в целом для более подробного анализа результатов классификации можно использовать PR-кривую, которая показывает взаимосвязь значения порога $t$ и значений точности и полноты. По оси $x$ отложим полноту, по оси $y$ - точность, и для каждого возможного значения порога (которых столько, сколько различных значений вероятностей для объектов в датасете выдал алгоритм) посчитаем значение точности и полноты и обозначим его на графике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "GLcmSjtIuMVv",
    "outputId": "2af0ce32-2d33-40ef-86c8-712351275aa2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision_array, recall_array, thresholds = precision_recall_curve(y, y_pred_prob)\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.plot(recall_array, precision_array)\n",
    "plt.title('PR-curve')\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lheYK5_-uMVx"
   },
   "source": [
    "Предположим, что нам необходимо получить точность не меньше $0.95$. Какой тогда нужно задать порог, чтобы значение полноты было оптимальным?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "bbLT64qHuMVx",
    "outputId": "c2bb3b7b-1705-437b-bc3c-672210d4471e"
   },
   "outputs": [],
   "source": [
    "big_precision_idx = np.where(precision_array >= 0.95)[0]\n",
    "big_precision_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "zSop8W5duMVz",
    "outputId": "50bfe21c-510f-4d2f-fd14-7c27ceee4e76"
   },
   "outputs": [],
   "source": [
    "recall_array[big_precision_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_precision_idx[np.argmax(recall_array[big_precision_idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "reRAgMhTuMV0",
    "outputId": "31f934d0-9592-4d9b-df6c-fcbce298fb8c"
   },
   "outputs": [],
   "source": [
    "t = thresholds[186]\n",
    "y_pred_t = threshold(y_pred_prob, t)\n",
    "print('t =', t)\n",
    "print('Precision:', precision_score(y, y_pred_t))\n",
    "print('Recall:', recall_score(y, y_pred_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NNcYMQucuMV2",
    "outputId": "9341828c-fcb4-4ad7-b216-3c1c21034733"
   },
   "outputs": [],
   "source": [
    "f1_score(y, y_pred_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsMDcOOVuMV3"
   },
   "source": [
    "Площадь под PR-кривой (AUC-PRC) показывает, насколько хорошо классификатор отранжировал объекты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g2sbU6pyuMV3",
    "outputId": "3b17dffe-91a8-4f6b-f900-fa43643614a4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc(recall_array, precision_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a26PmhRpuMV5"
   },
   "source": [
    "### ROC-кривая и AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KwVA2-MuMV5"
   },
   "source": [
    "Проанализировать результаты классификации (насколько хорошо алгоритм отранжировал объекты, присвоив им вероятности) также можно с помощью ROC-кривой. Принцип ее построения такой же, как и в PR-кривой - меняя значение порога, считать значения по осям. Только в этом случае по оси $x$ отложен False Positive Rate, по оси $y$ - True Positive Rate (который имеет ту же формулу, что и полнота):\n",
    "\n",
    "$$\n",
    "\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "fEmLfrEquMV6",
    "outputId": "2a9eddb6-c447-4af0-baf9-1c6a3ff3ac09"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_prob)\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC-curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWT_ihfiuMV8"
   },
   "source": [
    "Площадь под ROC-кривой показывает вероятность того, что случайно выбранная пара объектов, где один из них относится к положительному классу, а другой - к отрицательному, окажется отранжированной правильно с точки зрения вероятностей (алгоритм выдаст бОльшую вероятность в случае объекта положительного класса)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zcl3LsejuMV8",
    "outputId": "1b11b1ba-db20-405e-c167-3436aa14f328"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkwoYP1vuMV-"
   },
   "source": [
    "Как и доля правильных ответов, метрика AUC-ROC может ввести в заблуждение в случае задачи с несбалансированными классами."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Неделя5_Линейная-классификация.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
