{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №4\n",
    "\n",
    "Задание выполнил(а): Олег Голещихин\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "__Дата выдачи:__ 20.02.2021\n",
    "\n",
    "__Дедлайн:__ 7.03.2021 23:59\n",
    "\n",
    "### О задании\n",
    "\n",
    "Часть 1 содержит теоретические задачи на решающие деревья.\n",
    "\n",
    "Часть 2 содержит практическое задание на реализацию разбиения вершины в решающем дереве.\n",
    "\n",
    "Часть 3 содержит практическое задание на применение ансамблей в машинном обучении.\n",
    "\n",
    "Обратите внимание, что вам не только нужно написать код, но и в некоторых местах ответить на вопросы.\n",
    "\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "\n",
    "#### Theory  [4 балла]\n",
    "* [Задание 1](#task1) [1 балл]\n",
    "* [Задание 2](#task2) [1 балл]\n",
    "* [Задание 3](#task3) [1 балл]\n",
    "* [Задание 4](#task4) [1 балл]\n",
    "\n",
    "#### Решающие деревья [7 баллов]\n",
    "* [Задание 1](#task2_1) [1 балл]\n",
    "* [Задание 2](#task2_2) [1 балл]\n",
    "* [Задание 3](#task2_3) [1 балл]\n",
    "* [Задание 4](#task2_4) [2 балла]\n",
    "* [Задание 5](#task2_5) [1 балл]\n",
    "* [Задание 6](#task2_6) [1 балл]\n",
    "\n",
    "#### Ансамбли  [7 баллов]\n",
    "* [Задание 1](#task3_1) [1 балл]\n",
    "* [Задание 2](#task3_2) [1 балл]\n",
    "* [Задание 3](#task3_3) [1 балл]\n",
    "* [Задание 4](#task3_4) [2 балла]\n",
    "* [Задание 5](#task3_5) [1 балл]\n",
    "* [Задание 6](#task3_6) [1 балл]\n",
    "\n",
    "\n",
    "Итоговая оценка за домашнюю работу вычисляется по формуле: $$s \\cdot \\frac{10}{18},$$ где $s$ - сумма набранных балов. \n",
    "\n",
    "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 0.25 балла в день (от оценки в 10 бальной шкале), но получить отрицательную оценку нельзя.\n",
    "\n",
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов.\n",
    "\n",
    "### Формат сдачи\n",
    "\n",
    "Загрузка файлов с решениями происходит в системе [Anytask](https://anytask.org/course/770). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Теоритическая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 [1 балл] <a id=\"task1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В листе дерева оказываются 10 объектов, 8 из которых из одного класса, а 2 - из второго. Посчитайте (двоичную - с логарифмом по основанию 2) энтропию получившейся выборки в листе. Ответ округлите до двух знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "p1 = 8/10 # вероятность того, что объект окажется из первого класса\n",
    "p2 = 2/10 # вероятность того, что объект окажется из второго класса\n",
    "entropy = -(p1*np.log2(p1) + p2*np.log2(p2)) # рассчитаем этропию по формуле\n",
    "print('%.2f' % enthropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 [1 балл] <a id=\"task2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для приведенной ниже таблицы посчитайте, сколько нужно перебрать предикатов вида $[x_j = a]$ ([признак = какое-то значение]), чтобы построить первый узел решающего дерева.\n",
    "\n",
    "| $x_1$ | $x_2$ | $x_3$ | $y$ |\n",
    "|------|------|------|------|\n",
    "| A1 | A2 | A3 | A|\n",
    "| B1 | A2 | A3 | A|\n",
    "| C1 | B2 | A3 | B|\n",
    "| A1 | C2 | B3 | A|\n",
    "| B1 | D2 | A3 | B|\n",
    "| B1 | C2 | B3 | B|\n",
    "| C1 | D2 | B3 | A|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что признак x1 принимает 3 разных значения, признак x2 принимает 4 разных значения, признак x3 принимает 2 разных значения. Соответственно, нужно будет перебрать 9 предикатов (по общему числу разных значений, которые могут принимать признаки), чтобы выбрать из них наилучший (который лучше всего разделит выборку)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3 [1 балл] <a id=\"task3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя приведенную таблицу, по какому признаку следует формировать первый узел решающего дерева, если мы хотим предсказать $y$? В качестве критерия информативности использовать энтропию, в качестве критериев разделения - индикаторы $[x_j = a]$.\n",
    "\n",
    "| $x_1$ | $x_2$ | $x_3$ | $x_4$ | $y$ |\n",
    "|------|------|------|------|------|\n",
    "| A1 | A2 | A3 | A4 | A |\n",
    "| B1 | A2 | B3 | A4 | A |\n",
    "| C1 | C2 | A3 | A4 | A |\n",
    "| A1 | A2 | D3 | B4 | A |\n",
    "| C1 | B2 | C3 | A4 | B |\n",
    "| B1 | C2 | D3 | B4 | A |\n",
    "| A1 | B2 | B3 | A4 | A |\n",
    "| C1 | C2 | C3 | B4 | B |\n",
    "| B1 | B2 | C3 | B4 | B |\n",
    "| A1 | C2 | C3 | A4 | B |\n",
    "\n",
    "__Подсказка.__ *Внимательно посмотрите на данные.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что предикату [x3=C3] соответствует y=B, причем таким образом мы выбираем все четыре y=B, то есть полностью правильно разделяем наши ответы на классы A и B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** [x3=C3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4 [1 балл] <a id=\"task4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из перечисленных наборов объектов разных классов выберите набор с **наименьшей** энтропией.\n",
    "\n",
    "    1) 30 объектов класса 0, 10 объектов класса 1\n",
    "    2) 20 объектов класса 0, 10 объектов класса 1, 10 объектов класса 2\n",
    "    3) 35 объектов класса 0, 5 объектов класса 1, 5 объектов класса 2\n",
    "    4) 20 объектов класса 0, 20 объектов класса 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Энтропия набора 1: 0.56; 2: 1.04, 3: 0.68; 4: 0.69.\n",
      "Номер набора с наименьшей энтропией: 1\n"
     ]
    }
   ],
   "source": [
    "p1 = np.array([30/40, 10/40]) # вероятности первого набора\n",
    "p2 = np.array([20/40, 10/40, 10/40]) # вероятности второго набора\n",
    "p3 = np.array([35/45, 5/45, 5/45]) # вероятности третьего набора\n",
    "p4 = np.array([20/40, 20/40]) # вероятности четвертого набора\n",
    "\n",
    "entropy = list()\n",
    "for p in (p1, p2, p3, p4):\n",
    "    h = -np.sum(p*np.log(p))\n",
    "    entropy.append(h)\n",
    "\n",
    "print('Энтропия набора 1: %.2f; 2: %.2f, 3: %.2f; 4: %.2f.' % (entropy[0], entropy[1], entropy[2], entropy[3]))\n",
    "print('Номер набора с наименьшей энтропией:',np.argmin(entropy)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** 1 набор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Практика - решающие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части вам предстоит реализовать первое разбиение в решающем дереве своими руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (11, 6.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные представлены в виде словаря, у которого есть следующие ключи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим данные в виде `pandas.DataFrame`, также добавим в них целевую переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(data=boston['data'], columns=boston['feature_names'])\n",
    "X['target'] = boston['target']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение целевой переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x468 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('House price distribution')\n",
    "plt.xlabel('price')\n",
    "plt.ylabel('# samples')\n",
    "plt.hist(X['target'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним, как ищется разбиение в конкретной вершине. Пусть мы выбрали какой-то признак и порог. Обозначим $R_m$ - множество объектов в разбиваемой вершине, $j$ - номер признака, по которому происходит разбиение, $t$ - порог разбиения.\n",
    "\n",
    "Критерий ошибки выглядит следующим образом:\n",
    "\n",
    "$$\n",
    "Q(R_m, j, t) = \\frac{|R_\\ell|}{|R_m|}H(R_\\ell) + \\frac{|R_r|}{|R_m|}H(R_r) \\to \\min_{j, t},\n",
    "$$\n",
    "\n",
    "где $R_\\ell$ - множество объектов в левой вершине (поддереве), $R_r$ - множество объектов в правой вершине (поддереве), $|R|$ - число объектов в множестве $R$, а $H(R)$ - критерий информативности, с помощью которого можно оценить качество распределения целевой переменной среди объектов множества $R$. Например, в случае классификации $H(R)$ может быть выражено энтропией, а в случае регрессии - дисперсией.\n",
    "\n",
    "Мы хотим минимизировать $Q(R_m, j, t)$ по $j$ и $t$ - то есть подобрать такие $j$ и $t$, что для них значение $Q(R_m, j, t)$ будет минимальным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 [1 балл] <a id=\"task2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию подсчета критерия информативности. В данном случае мы решаем задачу регрессии, так что используйте дисперсию значений целевой переменной (колонка 'target').\n",
    "\n",
    "Сделайте так, чтобы даже для пустой таблицы (в которой нет ни одного объекта) выдавался численный ответ - 0, а не NaN. Возможно, в этом вам поможет функция `np.nan_to_num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(R):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    R - pd.DataFrame - характеризует собой набор объектов в вершине. В нашем случае R - это будет подмножество объектов из\n",
    "    изначальной таблицы X\n",
    "    \n",
    "    OUTPUT\n",
    "    H(R) - значение критерия информативности (дисперсия значений целевой переменной объектов в вершине)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    h = np.nan_to_num(np.var(R['target'], ddof=1))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "assert np.allclose(H(X), 84.5867235940986)\n",
    "assert np.allclose(H(pd.DataFrame(columns=X.columns)), 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 [1 балл]<a id=\"task2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию, которая разобьет объекты в данной вершине на две группы по заданному признаку `feature` и порогу `t`. Пусть в левую вершину попадут объекты, у которых значение `feature <= t`, а в правую - у которых значение `feature > t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_node(R_m, feature, t):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    R_m - pd.DataFrame - объекты в исходной вершине\n",
    "    feature - string - название столбца (признака)\n",
    "    t - float - порог признака feature, по которому разбиваем данные\n",
    "    \n",
    "    OUTPUT\n",
    "    R_l - pd.DataFrame - объекты, которые попали в левую вершину\n",
    "    R_r - pd.DataFrame - объекты, которые попали в правую вершину\n",
    "    \"\"\"\n",
    "    R_l = # YOUR CODE HERE\n",
    "    R_r = # YOUR CODE HERE\n",
    "    return R_l, R_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "R_l, R_r = split_node(X, 'ZN', 6.0)\n",
    "assert np.allclose(H(R_l), 73.7555971219894)\n",
    "assert np.allclose(H(R_r), 70.64116541353386)\n",
    "assert R_l['ZN'].max() <= 6.0\n",
    "assert R_r['ZN'].min() > 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3 [1 балл]<a id=\"task2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию, подсчитывающую значение критерия ошибки. Разделите данные по заданным признаку и порогу, посчитайте значения критериев информативности в полученных вершинах и получите результат по формуле в начале задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_error(R_m, feature, t):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    R_m - pd.DataFrame - объекты в исходной вершине\n",
    "    feature - string - название столбца (признака)\n",
    "    t - float - порог признака feature, по которому разбиваем данные\n",
    "    \n",
    "    OUTPUT\n",
    "    Q - float - значение критерия ошибки\n",
    "    \"\"\"\n",
    "    Q = # YOUR CODE HERE\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(q_error(X, 'ZN', 6.0), 72.93082666955256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4 [2 балла]<a id=\"task2_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда основные функции реализованы, можно перейти к непосредственному поиску оптимальных признака и порога. Для начала реализуйте функцию, с помощью которой можно найти оптимальный порог для разбиения вершины с помощью заданного признака. В качестве пороговых значений можно перебрать все уникальные значения признака, посчитать для каждого значение критерия ошибки, а затем выбрать пороговое значение, соответствующее наименьшему значению критерия ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_t(R_m, feature):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    R_m - pd.DataFrame - объекты в исходной вершине\n",
    "    feature - string - название столбца (признака)\n",
    "    \n",
    "    OUTPUT\n",
    "    t_opt - float - оптимальное значение порога (для которого значение критерия ошибки минимально)\n",
    "    t_array - list - список перебираемых пороговых значений\n",
    "    Q_array - list - список значений критерия ошибки, соответствующих перебранным пороговым значениям (для построения графика)\n",
    "    \"\"\"\n",
    "    Q_array = # YOUR CODE HERE\n",
    "    t_array = # YOUR CODE HERE\n",
    "    t_opt = # YOUR CODE HERE\n",
    "    return t_opt, t_array, Q_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "t_opt, t_array, Q_array = get_optimal_t(X, 'CRIM')\n",
    "assert np.allclose(t_opt, 6.65492)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите график зависимости значения критерия ошибки (`Q`) от порогового значения (`t`) при разбиении вершины по признаку `CRIM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5 [1 балл]<a id=\"task2_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь реализуйте функцию, с помощью которой можно определить также оптимальный признак. Внутри функции пройдитесь циклом по всем признакам, для каждого вызовите `get_optimal_t`, найдите оптимальный порог и минимальное значение критерия ошибки. Сравните полученные результаты (признаки, пороги и значения критерия ошибки для них) и выберите признак с порогом, соответствующие наименьшему значению критерия ошибки.\n",
    "\n",
    "**ИСКЛЮЧИТЕ ИЗ РАССМОТРЕНИЯ КОЛОНКУ 'target', ЭТО НЕ ПРИЗНАК!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_split(R_m):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    R_m - pd.DataFrame - объекты в исходной вершине\n",
    "    \n",
    "    OUTPUT\n",
    "    feature_opt - оптимальное значение признака для разбиения вершины\n",
    "    t_opt - оптимальное значение порога для разбиения вершины\n",
    "    \"\"\"\n",
    "    feature_opt = # YOUR CODE HERE\n",
    "    t_opt = # YOUR CODE HERE\n",
    "    return feature_opt, t_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "feature_opt, t_opt = get_optimal_split(X)\n",
    "print('Optimal feature:', feature_opt)\n",
    "print('Optimal t:', t_opt)\n",
    "assert feature_opt == 'RM'\n",
    "assert np.allclose(t_opt, 6.939)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6 [1 балл]<a id=\"task2_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразите на графике диаграмму рассеяния для объектов выборки со значением оптимального признака на одной оси и целевой переменной на другой. Нарисуйте линию, показывающую оптимальное разбиение по порогу (функция `plt.axvline`).\n",
    "\n",
    "Как вы можете интерпретировать то, что полученное разбиение - лучшее?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Практика - ансамбли"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной части будем работать [с задачей предсказания диабета у пациента](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение целевой переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x468 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Outcome'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 [1 балл]<a id=\"task3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте выборку на обучающую и тестовую части в отношении 70:30. Не забудьте отделить целевую переменную от признаков (чтобы случайно не включить ее в обучение как признак)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 [1 балл]<a id=\"task3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите [`BaggingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) на деревьях (параметр `base_estimator=DecisionTreeClassifier()`). Оцените качество классификации на тестовой выборке по метрикам accuracy, precision и recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3 [1 балл]<a id=\"task3_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучите Random Forest с числом деревьев, равным 50. Оцените качество классификации по тем же метрикам. Какая из двух построенных моделей показала себя лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4 [2 балл]<a id=\"task3_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для случайного леса проанализируйте значение AUC-ROC на этих же данных в зависимости от изменения параметров (можете сделать обычный перебор с обучением/тестированием в цикле):\n",
    "* `'n_estimators'` (можно перебрать около 10 значений из отрезка от 10 до 1500)\n",
    "* `'min_samples_leaf'` (сетку значений можете выбрать на ваше усмотрение)\n",
    "\n",
    "Постройте соответствующие графики зависимости AUC-ROC от этих параметров. Какие выводы вы можете сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5 [1 балл]<a id=\"task3_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для лучшей модели случайного леса посчитайте важность признаков и постройте bar plot с помощью функции [`plt.bar`](https://matplotlib.org/3.3.2/api/_as_gen/matplotlib.pyplot.bar.html). Какой признак оказался самым важным для определения диабета?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6 [1 балл]<a id=\"task3_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии со случайным лесом, переберите различные значения числа деревьев для [`GradientBoostingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) и постройте график зависимости AUC-ROC от числа деревьев. Что вы наблюдаете? Отличается ли этот график от аналогичного графика для случайного леса?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
